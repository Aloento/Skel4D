"""
å¿«é€Ÿæµ‹è¯•è„šæœ¬ - éªŒè¯Zero123Plus + StableKeypointsé›†æˆ
"""

import torch
import logging
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from zero123plus_stablekeypoints import Zero123PlusStableKeypoints

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def test_basic_functionality():
    """æµ‹è¯•åŸºæœ¬åŠŸèƒ½"""
    logger.info("Testing Zero123Plus + StableKeypoints integration...")
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    logger.info(f"Using device: {device}")
    
    try:
        # 1. åˆå§‹åŒ–æ¨¡å‹
        logger.info("Step 1: Initializing model...")
        model = Zero123PlusStableKeypoints(
            model_id="sudo-ai/zero123plus-v1.2",
            num_probes=5,  # å°‘é‡æ¢é’ˆç”¨äºå¿«é€Ÿæµ‹è¯•
            device=device
        )
        logger.info("âœ“ Model initialization successful")
        
        # 2. æµ‹è¯•æ¢é’ˆå‚æ•°
        logger.info("Step 2: Testing probe parameters...")
        probe_params = list(model.get_trainable_parameters())
        total_params = sum(p.numel() for p in probe_params)
        logger.info(f"âœ“ Trainable parameters: {total_params} (probes only)")
        
        # 3. æµ‹è¯•å‰å‘ä¼ æ’­
        logger.info("Step 3: Testing forward pass...")
        dummy_image = torch.randn(1, 3, 256, 256, device=device)
        
        # ä½¿ç”¨æ›´å°‘çš„æ¨ç†æ­¥æ•°è¿›è¡Œå¿«é€Ÿæµ‹è¯•
        result, info = model.forward_with_probes(
            dummy_image,
            num_inference_steps=5,
            guidance_scale=2.0
        )
        logger.info("âœ“ Forward pass successful")
        
        # 4. æ£€æŸ¥è¾“å‡º
        logger.info("Step 4: Checking outputs...")
        logger.info(f"Result type: {type(result)}")
        logger.info(f"Info keys: {list(info.keys())}")
        
        if 'attention_maps' in info:
            attention_shape = info['attention_maps'].shape
            logger.info(f"âœ“ Attention maps shape: {attention_shape}")
        
        if 'keypoints' in info:
            keypoints_shape = info['keypoints'].shape
            logger.info(f"âœ“ Keypoints shape: {keypoints_shape}")
            
            # æ˜¾ç¤ºä¸€äº›å…³é”®ç‚¹åæ ‡
            sample_keypoints = info['keypoints'][0, :3]  # å‰3ä¸ªå…³é”®ç‚¹
            logger.info(f"âœ“ Sample keypoints: {sample_keypoints}")
        
        if 'losses' in info:
            losses = info['losses']
            logger.info(f"âœ“ Losses: {losses}")
        
        # 5. æµ‹è¯•ä¿å­˜å’ŒåŠ è½½
        logger.info("Step 5: Testing save/load...")
        test_save_path = "test_probes.safetensors"
        model.save_probes(test_save_path)
        logger.info(f"âœ“ Saved probes to {test_save_path}")
        
        model.load_probes(test_save_path)
        logger.info(f"âœ“ Loaded probes from {test_save_path}")
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        Path(test_save_path).unlink(missing_ok=True)
        
        logger.info("ğŸ‰ All tests passed!")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_training_step():
    """æµ‹è¯•è®­ç»ƒæ­¥éª¤"""
    logger.info("\nTesting training step...")
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    try:
        # åˆå§‹åŒ–æ¨¡å‹å’Œä¼˜åŒ–å™¨
        model = Zero123PlusStableKeypoints(
            model_id="sudo-ai/zero123plus-v1.2",
            num_probes=3,  # æ›´å°‘çš„æ¢é’ˆ
            device=device
        )
        
        optimizer = torch.optim.AdamW(
            model.get_trainable_parameters(),
            lr=1e-4
        )
        
        # æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤
        dummy_image = torch.randn(1, 3, 256, 256, device=device)
        
        optimizer.zero_grad()
        
        result, info = model.forward_with_probes(
            dummy_image,
            num_inference_steps=3,  # å¾ˆå°‘çš„æ­¥æ•°
            guidance_scale=1.5
        )
        
        if 'losses' in info:
            total_loss = info['losses'].get('total_keypoint', torch.tensor(0.0))
            if total_loss.requires_grad:
                total_loss.backward()
                optimizer.step()
                logger.info(f"âœ“ Training step successful, loss: {total_loss.item():.4f}")
            else:
                logger.warning("Loss doesn't require gradients")
        else:
            logger.warning("No losses computed")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Training step failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_keypoint_extraction():
    """æµ‹è¯•å…³é”®ç‚¹æå–"""
    logger.info("\nTesting keypoint extraction...")
    
    try:
        # åˆ›å»ºæ¨¡æ‹Ÿæ³¨æ„åŠ›å›¾
        batch_heads = 2
        seq_len = 64  # 8x8çš„ç©ºé—´
        num_probes = 4
        
        # åˆ›å»ºä¸€äº›æœ‰å³°å€¼çš„æ³¨æ„åŠ›å›¾
        attention_maps = torch.randn(batch_heads, seq_len, num_probes)
        
        # åœ¨æŸäº›ä½ç½®æ·»åŠ å³°å€¼
        attention_maps[0, 10, 0] = 10.0  # æ¢é’ˆ0åœ¨ä½ç½®10æœ‰å³°å€¼
        attention_maps[0, 30, 1] = 8.0   # æ¢é’ˆ1åœ¨ä½ç½®30æœ‰å³°å€¼
        
        # åˆå§‹åŒ–æ¨¡å‹ï¼ˆä»…ç”¨äºæå–å…³é”®ç‚¹ï¼‰
        device = "cuda" if torch.cuda.is_available() else "cpu"
        model = Zero123PlusStableKeypoints(
            model_id="sudo-ai/zero123plus-v1.2",
            num_probes=num_probes,
            device=device
        )
        
        # æå–å…³é”®ç‚¹
        keypoints = model.extract_keypoints(attention_maps.to(device))
        
        logger.info(f"âœ“ Keypoints extracted: {keypoints.shape}")
        logger.info(f"âœ“ Sample keypoints: {keypoints[0]}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Keypoint extraction failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    logger.info("Starting comprehensive tests...")
    
    tests = [
        ("Basic Functionality", test_basic_functionality),
        ("Training Step", test_training_step),
        ("Keypoint Extraction", test_keypoint_extraction),
    ]
    
    results = {}
    for test_name, test_func in tests:
        logger.info(f"\n{'='*50}")
        logger.info(f"Running: {test_name}")
        logger.info(f"{'='*50}")
        
        results[test_name] = test_func()
    
    # æ€»ç»“
    logger.info(f"\n{'='*50}")
    logger.info("TEST SUMMARY")
    logger.info(f"{'='*50}")
    
    all_passed = True
    for test_name, passed in results.items():
        status = "âœ“ PASS" if passed else "âŒ FAIL"
        logger.info(f"{test_name}: {status}")
        all_passed = all_passed and passed
    
    if all_passed:
        logger.info("\nğŸ‰ All tests passed! The integration is working correctly.")
    else:
        logger.info("\nâš ï¸  Some tests failed. Please check the logs above.")
    
    return all_passed


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
